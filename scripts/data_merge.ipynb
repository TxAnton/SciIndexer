{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf24ce0",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import requests\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from functools import lru_cache\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a14f143",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf3f09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# JSON default serializer that knows how to convert Path and a few\n",
    "# common numpy/pandas types into JSON-serializable Python primitives.\n",
    "def json_default(o):\n",
    "    # Local imports to avoid import-order problems if this file is executed\n",
    "    # in a weird environment.\n",
    "    from pathlib import Path as _Path\n",
    "    import numpy as _np\n",
    "    import pandas as _pd\n",
    "\n",
    "    # pathlib.Path -> str\n",
    "    if isinstance(o, _Path):\n",
    "        return str(o)\n",
    "\n",
    "    # numpy scalar types -> Python scalar\n",
    "    if isinstance(o, (_np.integer, _np.floating, _np.bool_)):\n",
    "        return o.item()\n",
    "\n",
    "    # numpy arrays -> lists\n",
    "    if isinstance(o, _np.ndarray):\n",
    "        return o.tolist()\n",
    "\n",
    "    # pandas Timestamp -> ISO string\n",
    "    if isinstance(o, _pd.Timestamp):\n",
    "        return o.isoformat()\n",
    "\n",
    "    # bytes -> decode to utf-8 string\n",
    "    if isinstance(o, (bytes, bytearray)):\n",
    "        try:\n",
    "            return o.decode('utf-8')\n",
    "        except Exception:\n",
    "            return str(o)\n",
    "\n",
    "    if np.isnan(o):\n",
    "        return 'null' \n",
    "    # Let json raise the TypeError for types we don't know how to serialize.\n",
    "    raise TypeError(f\"Object of type {o.__class__.__name__} is not JSON serializable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df097e5c",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "\n",
    "datadir = Path(\"datasets\")\n",
    "pwild_dir = \"plantwild_v2\"\n",
    "pdoc_dir = 'PlantDoc-Dataset-windows-compatible'\n",
    "pvil_dir = 'PlantVillage-Dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8e064d",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "d1 = datadir/pwild_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e845ca",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# list(d1.iterdir())\n",
    "d1_classes =  set([i.name.lower() for i in d1.iterdir()])\n",
    "d1_classes\n",
    "d1_fullpath = [d1/i for i in d1_classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182032da",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "df_d1_classes = pd.DataFrame(columns=[\"fullpath\",\"fullname\",\"taxon\",\"desease\"], data=zip(\n",
    "    d1_fullpath,\n",
    "    d1_classes,\n",
    "    [None]*len(d1_classes),\n",
    "    [None]*len(d1_classes)))\n",
    "df_d1_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082bf520",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "d2 = datadir/pdoc_dir\n",
    "list(d2.iterdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a2f0cf",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "d2_classes = set()\n",
    "d21_classes = set()\n",
    "d22_classes = set()\n",
    "\n",
    "d21 = d2/\"train\"\n",
    "d22 = d2/\"test\"\n",
    "\n",
    "# d21_classes.update([i.name for i in d21.iterdir()])\n",
    "# d22_classes.update([i.name for i in d22.iterdir()])\n",
    "d2_all = [(d21/i.name,i.name) for i in d21.iterdir()] + [(d22/i.name,i.name) for i in d22.iterdir()]\n",
    "d2_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7549c74c",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "d2_fullpaths, d2_classes = zip(*d2_all)\n",
    "d2_fullpaths, d2_classes\n",
    "# d2_classes = d21_classes.union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ec0135",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_d2_classes = pd.DataFrame(columns=[\"fullpath\",\"fullname\",\"taxon\",\"desease\"], data=zip(\n",
    "    d2_fullpaths,\n",
    "    d2_classes,\n",
    "    [None]*len(d2_classes),\n",
    "    [None]*len(d2_classes)))\n",
    "df_d2_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a6a4e2",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "df_d1_classes = df_d1_classes.sort_values(\"fullname\")\n",
    "df_d2_classes = df_d2_classes.sort_values(\"fullname\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c1d99c",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "\n",
    "df_d1_classes.to_csv(\"data/d_wild_classes.csv\",index=False)\n",
    "df_d2_classes.to_csv(\"data/d_pdoc_classes.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586965f7",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# extract taxons manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9624bb10",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "df_d1_classes = pd.read_csv('data/d_wild_classes.csv', na_filter=False).reset_index(drop=True)\n",
    "df_d2_classes = pd.read_csv('data/d_pdoc_classes.csv', na_filter=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377764ba",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "def fill_desease(_df):\n",
    "    for i in _df.index:\n",
    "        name:str = _df.loc[i,\"taxon\"]\n",
    "        fullname:str = _df.loc[i,\"fullname\"].lower()\n",
    "        s_fullname = fullname.split(\" \")\n",
    "        name = s_fullname[0]\n",
    "        if name == \"bell\" and s_fullname[1] == \"pepper\":\n",
    "            name = \"bell pepper\"\n",
    "        _name = name.replace('_',\" \").split()\n",
    "        _fullname = fullname.replace('_',\" \").split()\n",
    "\n",
    "        for j in _name:\n",
    "            if j in _fullname:\n",
    "                _fullname.remove(j)\n",
    "            else:\n",
    "                print(j, _fullname)\n",
    "                raise Exception(\"wtf taxon name not in desease fullname\")\n",
    "        new_taxon = (' '.join(_name)).replace('soyabean','soybean')\n",
    "        new_desease = (' '.join(_fullname)).replace('healty','healthy')\n",
    "        _df.loc[i,\"desease\"] = new_desease\n",
    "        _df.loc[i,\"taxon\"] = new_taxon\n",
    "\n",
    "    return _df\n",
    "\n",
    "df_d2_classes = fill_desease(df_d2_classes)\n",
    "df_d1_classes = fill_desease(df_d1_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f199013d",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "df_d1_classes.to_csv(\"tmp.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788ada9a",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "d3 = datadir/pvil_dir\n",
    "\n",
    "d31 = d3/\"raw\"/\"color\"\n",
    "# d32 = d3/\"raw\"/\"segmented\"\n",
    "# d33 = d3/\"raw\"/\"grayscale\"\n",
    "d_full = d31\n",
    "\n",
    "list(d3.iterdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37d2de7",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "d3_all = set()\n",
    "\n",
    "d3_all.update([(d_full/i.name,i.name) for i in d31.iterdir()])\n",
    "d3_fullpath, d3_classes = zip(*d3_all)\n",
    "d3_fullpath, d3_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617355da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d3_classes.update([i.name for i in d31.iterdir()])\n",
    "# d3_classes.update([i.name for i in d32.iterdir()])\n",
    "# d3_classes.update([i.name for i in d33.iterdir()])\n",
    "\n",
    "df_d3_classes1 = pd.DataFrame(columns=[\"fullpath\",\"fullname\",\"taxon\",\"desease\"], data=zip(\n",
    "    d3_fullpath,\n",
    "    d3_classes,\n",
    "    [None]*len(d3_classes),\n",
    "    [None]*len(d3_classes)))\n",
    "df_d3_classes1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680efde3",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "\n",
    "d3_classes_split = []\n",
    "\n",
    "for ix in df_d3_classes1.index:\n",
    "    fullpath = df_d3_classes1.loc[ix,\"fullpath\"]\n",
    "    fullname = df_d3_classes1.loc[ix,\"fullname\"]\n",
    "    _taxon,_deseases = fullname.split(\"___\")\n",
    "    \n",
    "    taxon = ' '.join([i for i in _taxon.lower().split(\"_\") if not (\"(\" in i or \")\" in i)])\n",
    "    taxon = taxon.replace(\"pepper, bell\",\"bell pepper\")\n",
    "    deseases = [i.replace(\"_\",\" \").lower().removeprefix(taxon).replace('-',\"\").replace('  ',\" \").strip() for i in _deseases.split(\" \")]\n",
    "    # print(taxon,deseases)\n",
    "\n",
    "    for d in deseases:\n",
    "        d3_classes_split.append((fullpath,fullname,taxon,d,\"pvil\"))\n",
    "    # break\n",
    "    \n",
    "d3_classes_split\n",
    "\n",
    "df_d3_classes = df_d3_classes1 = pd.DataFrame(columns=[\"fullpath\",\"fullname\",\"taxon\",\"desease\",\"src\"], data=d3_classes_split)\n",
    "df_d3_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf8f50f",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "df_d1_classes[\"src\"] = ['wild']*len(df_d1_classes)\n",
    "df_d2_classes[\"src\"] = ['pdoc']*len(df_d2_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980c8738",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d01998",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "df_concat = pd.concat([df_d1_classes,df_d2_classes,df_d3_classes])\n",
    "df_concat = df_concat.sort_values(['taxon','desease','fullname'])\n",
    "df_concat.to_csv(\"data/d_concat_classes2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3709ca",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "u_taxons = df_concat['taxon'].unique()\n",
    "u_taxons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef8ce39",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "\n",
    "data = []\n",
    "\n",
    "for taxon in u_taxons:\n",
    "    _df = df_concat[df_concat[\"taxon\"]==taxon]\n",
    "    u_deseases = _df['desease'].unique()\n",
    "    for desease in u_deseases:\n",
    "        __df = _df[_df[\"desease\"]==desease]\n",
    "        _fullnames = __df[\"fullname\"].to_list()\n",
    "        pdoc_name = __df[__df[\"src\"]==\"pdoc\"][\"fullpath\"].to_list()\n",
    "        wild_name = __df[__df[\"src\"]==\"wild\"][\"fullpath\"].to_list()\n",
    "        pvil_name = __df[__df[\"src\"]==\"pvil\"][\"fullpath\"].unique().tolist()\n",
    "        _d = {\"wild_name\":wild_name,\n",
    "              \"pdoc_name\":pdoc_name,\n",
    "              \"pvil_name\":pvil_name,\n",
    "              \"taxon\":taxon,\n",
    "              \"taxon_q\":None,\n",
    "              \"taxon_eppo\":None,\n",
    "              \"desease\":desease,\n",
    "              \"desease_q\":None}\n",
    "        data.append(_d)\n",
    "        # print(_fullnames)\n",
    "        # break\n",
    "    # break\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63ce7d7",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00882c3b",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "df_data1 = pd.DataFrame(data=data)\n",
    "df_data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e253a43",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "def saveify(_df):\n",
    "    _df = _df.copy()\n",
    "    col = _df.columns\n",
    "    for c in col:\n",
    "        _df[c] = _df[c].apply(lambda x:json.dumps(x, default=json_default)).apply(lambda x:x if not x==\"NaN\" else 'null')\n",
    "    return _df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7914aa2",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# def saveify(_df):\n",
    "#     _df = _df.copy()\n",
    "#     col = _df.columns\n",
    "#     for c in col:\n",
    "#         _df[c] = _df[c].apply(lambda x:json.dumps(x))\n",
    "#     return _df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639d6ae3",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "df_data1_save = saveify(df_data1)\n",
    "df_data1_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b115fb8",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "df_data1_save.to_csv(\"data/d_corr13.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b1cbfb",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "\n",
    "from typing import Annotated, Dict, List, Literal, Optional, Tuple, Union\n",
    "from fuzzywuzzy import process\n",
    "t_q = str\n",
    "t_q_guaranteed = str\n",
    "t_eppo = str\n",
    "t_eppo_guaranteed = str\n",
    "t_sparql_response = List[Optional[Dict]]\n",
    "t_raw_sparql_response = Dict[str,Dict[str,List]]\n",
    "t_triplet = Tuple[str,Optional[t_q],Optional[t_eppo]]\n",
    "t_triplet_list = List[t_triplet]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3a9ba4",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "\n",
    "tuplify = lambda arr: tuple(i if type(i) in (str,type(None)) else tuple(i) for i in arr if i or i is None) if arr else ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67987c39",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "0/0\n",
    "\n",
    "@lru_cache(maxsize=None)\n",
    "def read_local_eppo():\n",
    "    _df1 = pd.read_csv(\"eppo/gafname.txt\")\n",
    "    _df2 = pd.read_csv(\"eppo/gainame.txt\")\n",
    "    _df3 = pd.read_csv(\"eppo/pflname.txt\")\n",
    "    _df = pd.concat((_df1,_df2,_df3))    \n",
    "    _names = _df[\"fullname\"].dropna().tolist()\n",
    "    return _df, _names\n",
    "\n",
    "@lru_cache(maxsize=None)\n",
    "def _search_local_eppo_names(name: str, limit) -> List[Tuple[str,int]]:\n",
    "    _df,_names = read_local_eppo()\n",
    "    column_as_list = _names\n",
    "    res = tuplify(process.extract(name, column_as_list,limit=limit))\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bc8234",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "\n",
    "def search_local_eppo_name(name: str, limit = 20, _dfindings={}, threshold=90) -> Optional[t_eppo]:\n",
    "    _eppo_df,_names = read_local_eppo()\n",
    "    \n",
    "    if name in _dfindings:\n",
    "        _res = _dfindings[name]\n",
    "    else:\n",
    "        _res = _search_local_eppo_names(name, limit)\n",
    "    trg = _res[0]\n",
    "    \n",
    "    if trg[1] <= threshold:\n",
    "        return None\n",
    "    else:\n",
    "        eppo = _eppo_df[_eppo_df.fullname==trg[0]].code.iloc[0]\n",
    "        return eppo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b21e313",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hosts_u_df = pd.read_csv(\"data/plant_taxonomy4_e.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c1471b",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_find_names = dict()\n",
    "for taxon in tqdm(u_taxons):\n",
    "    f_eppo = search_local_eppo_name(taxon)\n",
    "    _df = hosts_u_df[hosts_u_df[\"eppo\"]==f_eppo]\n",
    "    if len(_df):\n",
    "        _s = _df.iloc[0]\n",
    "        eppo = _s[\"eppo\"]\n",
    "        q = _s[\"q\"]\n",
    "    else:\n",
    "        eppo = q = None\n",
    "    d_find_names[taxon] = (q,eppo)\n",
    "\n",
    "d_find_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222985ef",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "df_data2 = df_data1.copy()\n",
    "\n",
    "\n",
    "for i in df_data2.index:\n",
    "    taxon = df_data1.loc[i,\"taxon\"]\n",
    "    _t = d_find_names.get(taxon)\n",
    "    if _t:\n",
    "        df_data2.loc[i,\"taxon_q\"] = _t[0] if not type(_t[0])==float else None\n",
    "        df_data2.loc[i,\"taxon_eppo\"] = _t[1]\n",
    "    \n",
    "df_data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc864c61",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "df_data2_save = saveify(df_data2)\n",
    "df_data2_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd61aab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data2_save.to_csv(\"data/d_corr16.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8610c91c",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "_df_data2 = df_data2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fb4307",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# df_data2.wild_name = df_data2.wild_name.apply(lambda x:bool(x))\n",
    "# df_data2.pdoc_name = df_data2.pdoc_name.apply(lambda x:bool(x))\n",
    "# df_data2.pvil_name = df_data2.pdoc_name.apply(lambda x:bool(x))\n",
    "# df_data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a60ece9",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "df_data2.to_csv(\"test.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b600694",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_aps = pd.read_csv('data/APS_plant_diseases.csv', na_filter=False).reset_index(drop=True)\n",
    "\n",
    "df_aps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac757f91",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Нормализуем регистр\n",
    "df_aps['Disease'] = df_aps['Disease'].str.lower().str.strip()\n",
    "df_aps['Afflict'] = df_aps['Afflict'].str.lower().str.strip()\n",
    "\n",
    "df_aps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906711fe",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "\n",
    "matched = df_data2.merge(\n",
    "    df_aps,\n",
    "    left_on=['taxon', 'desease'],\n",
    "    right_on=['Afflict', 'Disease'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "matched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a62d526",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "matched.to_csv(\"test.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7037c6b",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "\n",
    "from rapidfuzz import process, fuzz\n",
    "\n",
    "def fuzzy_match_disease(row, aps_subset):\n",
    "    if pd.notna(row['desease']):\n",
    "        match = process.extractOne(\n",
    "            row['desease'],\n",
    "            aps_subset['Disease'],\n",
    "            scorer=fuzz.token_sort_ratio\n",
    "        )\n",
    "        if match and match[1] > 85:\n",
    "            return aps_subset.loc[aps_subset['Disease'] == match[0]].iloc[0]\n",
    "    return pd.Series()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a37dd5b",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Применяем для тех, кто не сматчился напрямую\n",
    "unmatched = matched[matched['Category'].isna()]\n",
    "fuzzy_results = unmatched.apply(lambda x: fuzzy_match_disease(x, df_aps), axis=1)\n",
    "fuzzy_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7706952",
   "metadata": {},
   "outputs": [],
   "source": [
    "matched.update(fuzzy_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7fb098",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "_matched = matched.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8dc659c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "matched[\"wild_path\"]= matched[\"wild_name\"]\n",
    "matched[\"pdoc_path\"]= matched[\"pdoc_name\"]\n",
    "matched[\"pvil_path\"]= matched[\"pvil_name\"]\n",
    "matched[\"wild_name\"] = matched[\"wild_name\"].apply(lambda x: bool(x))\n",
    "matched[\"pdoc_name\"] = matched[\"pdoc_name\"].apply(lambda x: bool(x))\n",
    "matched[\"pvil_name\"] = matched[\"pvil_name\"].apply(lambda x: bool(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21aa928a",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "matched_save = saveify(matched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746facc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "matched_save.to_csv(\"data/d_corr19.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f007c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "taxons = matched[\"taxon\"].unique().tolist()\n",
    "taxons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c7ad0c",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# matched_todict = matched.to_dict(orient='records')\n",
    "# matched_todict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa68458",
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_dict = {}\n",
    "for taxon in taxons:\n",
    "    \n",
    "    _df_taxon = matched[matched[\"taxon\"]==taxon]\n",
    "    \n",
    "    diseases = _df_taxon['desease'].unique().tolist()\n",
    "    d = {}\n",
    "    for disease in diseases:\n",
    "        _df_desease = _df_taxon[_df_taxon[\"desease\"]==disease]\n",
    "        _json_desease = _df_desease.to_dict(orient='records')[0]\n",
    "        # if len(_json_desease)>1:\n",
    "        #     print(taxon,disease,_json_desease)\n",
    "        d[disease] = _json_desease\n",
    "    \n",
    "    matched_dict[taxon] = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be0c704",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "\n",
    "with open(\"data/matched_dict.json\",'w+') as fd:\n",
    "    json.dump(matched_dict,fd, indent=4, default=json_default)\n",
    "# matched_dict    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9b3514",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "\n",
    "with open(\"data/matched_dict.json\",'r+') as fd:\n",
    "    matched_dict = json.load(fd)\n",
    "\n",
    "# disease = matched_dict[\"wheat\"][\"leaf rust\"]\n",
    "disease = matched_dict[\"apple\"][\"scab\"]\n",
    "pathes = disease[\"wild_path\"] + disease[\"pdoc_path\"] + disease[\"pvil_path\"]\n",
    "# pathes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27afa9ee",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# all apple scab images\n",
    "files = ([list(Path(i).iterdir()) for i in pathes])\n",
    "flat_files = [item for sublist in files for item in sublist]\n",
    "len(flat_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a31ac5",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "pathes = matched_dict[\"wheat\"][\"leaf rust\"][\"wild_path\"] # ['datasets/plantwild_v2/wheat leaf rust']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84215a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf392a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da38d01b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
